#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç 04: K-means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞—Å–µ–ª—ë–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤

–¶–µ–ª—å: –†–∞–∑–±–∏—Ç—å 128 –ù–ü –Ω–∞ —Ç–∏–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –≥—Ä—É–ø–ø—ã (5-7 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)
–ú–µ—Ç–æ–¥: K-means –Ω–∞ PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö (15 —à—Ç—É–∫)
–†–µ–∑—É–ª—å—Ç–∞—Ç:
    - clusters.csv (settlement_id, cluster_id, cluster_name)
    - cluster_profiles.json (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º)
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score
import warnings

warnings.filterwarnings('ignore')


def elbow_method(X, k_range=(3, 10)):
    """–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ k"""
    print("\nüìâ Elbow Method: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")

    inertias = []
    silhouette_scores = []
    davies_bouldin_scores = []

    for k in range(k_range[0], k_range[1] + 1):
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=20, max_iter=500)
        labels = kmeans.fit_predict(X)

        inertias.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(X, labels))
        davies_bouldin_scores.append(davies_bouldin_score(X, labels))

        print(f"   k={k}: inertia={kmeans.inertia_:.2f}, "
              f"silhouette={silhouette_scores[-1]:.3f}, "
              f"davies_bouldin={davies_bouldin_scores[-1]:.3f}")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º k —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º silhouette score
    best_k_idx = np.argmax(silhouette_scores)
    best_k = range(k_range[0], k_range[1] + 1)[best_k_idx]

    print(f"\n   üèÜ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ k = {best_k} (silhouette={silhouette_scores[best_k_idx]:.3f})")

    return {
        'k_values': list(range(k_range[0], k_range[1] + 1)),
        'inertias': inertias,
        'silhouette_scores': silhouette_scores,
        'davies_bouldin_scores': davies_bouldin_scores,
        'best_k': best_k
    }


def assign_cluster_names(cluster_stats_df, settlements_df):
    """–ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–µ –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""

    cluster_names = {}

    # –ü–æ–ª—É—á–∞–µ–º –¢–û–ü-3 –ù–ü –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    for cluster_id in sorted(cluster_stats_df['cluster_id'].unique()):
        cluster_data = settlements_df[settlements_df['cluster_id'] == cluster_id]

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞
        avg_population = cluster_data['population'].mean() if 'population' in cluster_data.columns else 0
        count = len(cluster_data)
        arctic_ratio = cluster_data['is_arctic'].mean() if 'is_arctic' in cluster_data.columns else 0

        # –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π —Ä–µ–≥–∏–æ–Ω
        top_region = cluster_data['region_name'].mode()[0] if 'region_name' in cluster_data.columns and not cluster_data['region_name'].empty else "–†–∞–∑–Ω—ã–µ"

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ —Ä–µ–≥–∏–æ–Ω—É
        is_hmao_yanao = cluster_data['region_name'].str.contains('–•–∞–Ω—Ç—ã-–ú–∞–Ω—Å–∏–π—Å–∫–∏–π|–Ø–º–∞–ª–æ-–ù–µ–Ω–µ—Ü–∫–∏–π', na=False).mean() > 0.5
        is_arctic = arctic_ratio > 0.5

        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏—è –∏–º—ë–Ω
        if count == 1:
            # –ï–¥–∏–Ω–∏—á–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã - –∞–Ω–æ–º–∞–ª–∏–∏
            name = f"–ê–Ω–æ–º–∞–ª–∏—è: {cluster_data['settlement_name'].iloc[0]}"
        elif avg_population > 15000:
            if is_hmao_yanao:
                name = "–ù–µ—Ñ—Ç–µ–≥–∞–∑–æ–≤—ã–µ –ø–æ—Å—ë–ª–∫–∏ (–•–ú–ê–û/–Ø–ù–ê–û)"
            else:
                name = "–ö—Ä—É–ø–Ω—ã–µ –ü–ì–¢/–≥–æ—Ä–æ–¥–∞"
        elif avg_population > 7000:
            if is_arctic:
                name = "–ê—Ä–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ü–µ–Ω—Ç—Ä—ã"
            else:
                name = "–°—Ä–µ–¥–Ω–∏–µ –≥–æ—Ä–æ–¥–∞/–ü–ì–¢"
        elif avg_population > 4000:
            if is_arctic:
                name = "–ê—Ä–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å—ë–ª–∞"
            elif is_hmao_yanao:
                name = "–ú–∞–ª—ã–µ –Ω–µ—Ñ—Ç–µ–≥–∞–∑–æ–≤—ã–µ –ü–ì–¢"
            else:
                name = "–°—Ç–∞–±–∏–ª—å–Ω—ã–µ —Å—ë–ª–∞"
        elif avg_population > 2000:
            if is_arctic:
                name = "–ú–∞–ª—ã–µ –∞—Ä–∫—Ç–∏—á–µ—Å–∫–∏–µ –ù–ü"
            else:
                name = "–°–µ–ª—å—Å–∫–∏–µ –ø–æ—Å–µ–ª–µ–Ω–∏—è"
        else:
            name = "–ú–∞–ª—ã–µ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ù–ü"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏
        base_name = name
        counter = 1
        while name in cluster_names.values():
            name = f"{base_name} (–≤–∞—Ä.{counter})"
            counter += 1

        cluster_names[cluster_id] = name

    return cluster_names


def run_clustering():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""

    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    script_dir = Path(__file__).parent
    data_dir = script_dir.parent / 'results' / 'data'
    analysis_dir = script_dir.parent / 'results' / 'analysis'

    # =============================
    # 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
    # =============================
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

    # PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    pca_df = pd.read_csv(data_dir / 'pca_components.csv')
    print(f"   ‚úÖ PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {pca_df.shape[0]} –ù–ü √ó {pca_df.shape[1]-1} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç")

    # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏)
    settlements_df = pd.read_csv(data_dir / 'settlements_with_indicators.csv')
    print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ –ù–ü: {settlements_df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {settlements_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–∏—Å–∫–ª—é—á–∞–µ–º settlement_id)
    pca_columns = [col for col in pca_df.columns if col.startswith('PC')]
    X_pca = pca_df[pca_columns].values

    print(f"   ‚ÑπÔ∏è  –ú–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {X_pca.shape[0]} √ó {X_pca.shape[1]}")

    # =============================
    # 2. ELBOW METHOD
    # =============================
    elbow_results = elbow_method(X_pca, k_range=(3, 10))
    best_k = elbow_results['best_k']

    # =============================
    # 3. –§–ò–ù–ê–õ–¨–ù–ê–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø
    # =============================
    print(f"\nüéØ –ó–∞–ø—É—Å–∫ K-means —Å k={best_k}...")

    kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=20, max_iter=500)
    cluster_labels = kmeans.fit_predict(X_pca)

    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    silhouette = silhouette_score(X_pca, cluster_labels)
    davies_bouldin = davies_bouldin_score(X_pca, cluster_labels)

    print(f"   ‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    print(f"   üìä Silhouette Score: {silhouette:.3f} (—á–µ–º –±–ª–∏–∂–µ –∫ 1, —Ç–µ–º –ª—É—á—à–µ)")
    print(f"   üìä Davies-Bouldin Index: {davies_bouldin:.3f} (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)")

    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫ –¥–∞–Ω–Ω—ã–º
    pca_df['cluster_id'] = cluster_labels
    settlements_df['cluster_id'] = cluster_labels

    # =============================
    # 4. –ê–ù–ê–õ–ò–ó –ö–õ–ê–°–¢–ï–†–û–í
    # =============================
    print("\nüìä –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
    print("=" * 80)

    cluster_stats = []

    for cluster_id in sorted(np.unique(cluster_labels)):
        cluster_mask = settlements_df['cluster_id'] == cluster_id
        cluster_data = settlements_df[cluster_mask]

        stats = {
            'cluster_id': int(cluster_id),
            'count': len(cluster_data),
            'avg_population': float(cluster_data['population'].mean()) if 'population' in cluster_data.columns else None,
            'total_population': int(cluster_data['population'].sum()) if 'population' in cluster_data.columns else None,
            'arctic_count': int(cluster_data['is_arctic'].sum()) if 'is_arctic' in cluster_data.columns else None,
        }

        cluster_stats.append(stats)

        print(f"\nüîµ –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}:")
        print(f"   ‚Ä¢ –ö–æ–ª-–≤–æ –ù–ü: {stats['count']}")
        if stats['avg_population']:
            print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –Ω–∞—Å–µ–ª–µ–Ω–∏–µ: {stats['avg_population']:.0f}")
        if stats['total_population']:
            print(f"   ‚Ä¢ –û–±—â–µ–µ –Ω–∞—Å–µ–ª–µ–Ω–∏–µ: {stats['total_population']:,}")
        if stats['arctic_count'] is not None:
            print(f"   ‚Ä¢ –ê—Ä–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ù–ü: {stats['arctic_count']}")

        # –ü—Ä–∏–º–µ—Ä—ã –ù–ü –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ç–æ–ø-3 –ø–æ –Ω–∞—Å–µ–ª–µ–Ω–∏—é)
        top_settlements = cluster_data.nlargest(3, 'population')[['settlement_name', 'population']] \
            if 'population' in cluster_data.columns else None

        if top_settlements is not None and not top_settlements.empty:
            print(f"   ‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã –ù–ü:")
            for _, row in top_settlements.iterrows():
                print(f"      - {row['settlement_name']}: {row['population']:,.0f} —á–µ–ª.")

    print("\n" + "=" * 80)

    # =============================
    # 5. –ü–†–ò–°–í–û–ï–ù–ò–ï –ò–ú–Å–ù –ö–õ–ê–°–¢–ï–†–ê–ú
    # =============================
    print("\nüè∑Ô∏è  –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ —Ç–∏–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏–º—ë–Ω –∫–ª–∞—Å—Ç–µ—Ä–∞–º...")

    cluster_stats_df = pd.DataFrame(cluster_stats)
    cluster_names = assign_cluster_names(cluster_stats_df, settlements_df)

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–µ–Ω–∞ –∫ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞–º
    settlements_df['cluster_name'] = settlements_df['cluster_id'].map(cluster_names)

    print("\n   –ò–º–µ–Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
    for cluster_id, name in cluster_names.items():
        count = (settlements_df['cluster_id'] == cluster_id).sum()
        print(f"      –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: '{name}' ({count} –ù–ü)")

    # =============================
    # 6. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
    # =============================
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

    # 6.1. clusters.csv (–∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    clusters_output = settlements_df[[
        'settlement_id', 'settlement_name', 'region_name',
        'population', 'cluster_id', 'cluster_name'
    ]].copy()

    clusters_file = data_dir / 'clusters.csv'
    clusters_output.to_csv(clusters_file, index=False)
    print(f"   ‚úÖ {clusters_file}")

    # 6.2. cluster_profiles.json
    profiles = []
    for cluster_id in sorted(cluster_names.keys()):
        cluster_data = settlements_df[settlements_df['cluster_id'] == cluster_id]

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –≤—Å–µ–º —á–∏—Å–ª–æ–≤—ã–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º
        numeric_cols = cluster_data.select_dtypes(include=[np.number]).columns
        means = cluster_data[numeric_cols].mean().to_dict()

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        profile = {
            'cluster_id': int(cluster_id),
            'cluster_name': cluster_names[cluster_id],
            'count': len(cluster_data),
            'mean_values': {k: float(v) for k, v in means.items() if not pd.isna(v)}
        }

        profiles.append(profile)

    profiles_file = data_dir / 'cluster_profiles.json'
    with open(profiles_file, 'w', encoding='utf-8') as f:
        json.dump(profiles, f, ensure_ascii=False, indent=2)
    print(f"   ‚úÖ {profiles_file}")

    # 6.3. –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    metrics = {
        'best_k': int(best_k),
        'silhouette_score': float(silhouette),
        'davies_bouldin_score': float(davies_bouldin),
        'elbow_method': elbow_results
    }

    metrics_file = analysis_dir / 'clustering_metrics.json'
    with open(metrics_file, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)
    print(f"   ‚úÖ {metrics_file}")

    # =============================
    # 7. –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê
    # =============================
    print("\n" + "=" * 80)
    print("‚úÖ –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 80)
    print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {best_k}")
    print(f"üìä Silhouette Score: {silhouette:.3f}")
    print(f"üìä Davies-Bouldin Index: {davies_bouldin:.3f}")
    print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {data_dir}")
    print("=" * 80)

    return {
        'clusters_df': settlements_df,
        'cluster_names': cluster_names,
        'metrics': metrics
    }


if __name__ == '__main__':
    run_clustering()
