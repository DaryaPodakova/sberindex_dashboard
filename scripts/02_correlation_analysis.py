#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç 02: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ + PCA

–¶–µ–ª—å: –ù–∞–π—Ç–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –∏–∑ 93 –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π POAD
–†–µ–∑—É–ª—å—Ç–∞—Ç:
    - correlation_matrix.csv (93√ó93)
    - top_10_factors.csv (—Ç–æ–ø-10 –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å –Ω–∞—Å–µ–ª–µ–Ω–∏–µ–º)
    - pca_components.csv (–≥–ª–∞–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)
    - pca_explained_variance.csv (–¥–æ–ª—è –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏)
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import warnings

warnings.filterwarnings('ignore')


def run_correlation_analysis():
    """–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ POAD –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π"""

    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    script_dir = Path(__file__).parent
    data_dir = script_dir.parent / 'results' / 'data'
    analysis_dir = script_dir.parent / 'results' / 'analysis'
    analysis_dir.mkdir(parents=True, exist_ok=True)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ settlements_with_indicators.csv...")
    df = pd.read_csv(data_dir / 'settlements_with_indicators.csv')

    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –ù–ü")
    print(f"   ‚ÑπÔ∏è  –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")

    # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ POAD)
    # –ò—Å–∫–ª—é—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (settlement_id, names, coordinates, etc.)
    meta_columns = [
        'settlement_id', 'settlement_name', 'region_name', 'municipality_up_name',
        'municipality_down_name', 'settlement_type', 'population', 'is_arctic',
        'latitude', 'longitude'
    ]

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    indicator_columns = [col for col in numeric_columns if col not in meta_columns]

    print(f"   ‚ÑπÔ∏è  –ü–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π POAD: {len(indicator_columns)}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
    X = df[indicator_columns].copy()

    # –£–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ > 50%
    missing_pct = (X.isna().sum() / len(X)) * 100
    columns_to_keep = missing_pct[missing_pct <= 50].index.tolist()

    print(f"\nüßπ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ > 50%...")
    print(f"   ‚Ä¢ –ë—ã–ª–æ: {len(indicator_columns)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")
    print(f"   ‚Ä¢ –û—Å—Ç–∞–ª–æ—Å—å: {len(columns_to_keep)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")

    X_clean = X[columns_to_keep].copy()

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–æ–ø—É—Å–∫–∏ –º–µ–¥–∏–∞–Ω–æ–π
    X_clean = X_clean.fillna(X_clean.median())

    print(f"   ‚úÖ –ú–∞—Ç—Ä–∏—Ü–∞ –¥–∞–Ω–Ω—ã—Ö: {X_clean.shape[0]} –ù–ü √ó {X_clean.shape[1]} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")

    # =============================
    # 1. –ö–û–†–†–ï–õ–Ø–¶–ò–û–ù–ù–ê–Ø –ú–ê–¢–†–ò–¶–ê
    # =============================
    print("\nüìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã...")
    corr_matrix = X_clean.corr()

    corr_file = analysis_dir / 'correlation_matrix.csv'
    corr_matrix.to_csv(corr_file)
    print(f"   ‚úÖ {corr_file}")
    print(f"   ‚ÑπÔ∏è  –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {corr_matrix.shape[0]}√ó{corr_matrix.shape[1]}")

    # =============================
    # 2. –¢–û–ü-10 –§–ê–ö–¢–û–†–û–í
    # =============================
    print("\nüèÜ –ü–æ–∏—Å–∫ —Ç–æ–ø-10 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å –Ω–∞—Å–µ–ª–µ–Ω–∏–µ–º...")

    # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ population –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ
    if 'population' in df.columns:
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è —Å –Ω–∞—Å–µ–ª–µ–Ω–∏–µ–º
        population_corr = X_clean.corrwith(df['population']).abs().sort_values(ascending=False)

        # –¢–æ–ø-10 –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
        top_10 = population_corr.head(10)

        print("\n   TOP-10 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å –Ω–∞—Å–µ–ª–µ–Ω–∏–µ–º):")
        for i, (indicator, corr_val) in enumerate(top_10.items(), 1):
            print(f"      {i}. {indicator}: r={corr_val:.3f}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        top_10_df = pd.DataFrame({
            'rank': range(1, 11),
            'indicator_code': top_10.index,
            'correlation_with_population': top_10.values
        })

        top_10_file = data_dir / 'top_10_factors.csv'
        top_10_df.to_csv(top_10_file, index=False)
        print(f"\n   ‚úÖ {top_10_file}")

    else:
        print("   ‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ 'population' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å –Ω–∞—Å–µ–ª–µ–Ω–∏–µ–º.")
        top_10_df = None

    # =============================
    # 3. PCA (–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏)
    # =============================
    print("\nüî¨ PCA: —Å–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 93 ‚Üí 15 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç...")

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_clean)

    # PCA —Å 15 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
    n_components = min(15, X_clean.shape[1], X_clean.shape[0])
    pca = PCA(n_components=n_components, random_state=42)
    X_pca = pca.fit_transform(X_scaled)

    print(f"   ‚úÖ PCA –≤—ã–ø–æ–ª–Ω–µ–Ω: {X_clean.shape[1]} ‚Üí {n_components} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç")

    # –î–æ–ª—è –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏
    explained_variance = pca.explained_variance_ratio_
    cumulative_variance = np.cumsum(explained_variance)

    print(f"\n   üìà –î–æ–ª—è –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏:")
    for i in range(min(10, n_components)):
        print(f"      PC{i+1}: {explained_variance[i]*100:.2f}% (Á¥ØË®à: {cumulative_variance[i]*100:.2f}%)")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–ª–∞–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    pca_df = pd.DataFrame(
        X_pca,
        columns=[f'PC{i+1}' for i in range(n_components)]
    )
    pca_df.insert(0, 'settlement_id', df['settlement_id'].values)

    pca_file = data_dir / 'pca_components.csv'
    pca_df.to_csv(pca_file, index=False)
    print(f"\n   ‚úÖ {pca_file}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º explained variance
    variance_df = pd.DataFrame({
        'component': [f'PC{i+1}' for i in range(n_components)],
        'explained_variance_ratio': explained_variance,
        'cumulative_variance_ratio': cumulative_variance
    })

    variance_file = analysis_dir / 'pca_explained_variance.csv'
    variance_df.to_csv(variance_file, index=False)
    print(f"   ‚úÖ {variance_file}")

    # =============================
    # 4. FEATURE IMPORTANCE (–∏–∑ PCA)
    # =============================
    print("\nüîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ PCA...")

    # Loadings –º–∞—Ç—Ä–∏—Ü–∞ (–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã √ó –ø—Ä–∏–∑–Ω–∞–∫–∏)
    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)
    loadings_df = pd.DataFrame(
        loadings,
        columns=[f'PC{i+1}' for i in range(n_components)],
        index=X_clean.columns
    )

    # –°—á–∏—Ç–∞–µ–º –æ–±—â—É—é –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞ (—Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ loadings –ø–æ –≤—Å–µ–º PC)
    feature_importance = (loadings_df ** 2).sum(axis=1).sort_values(ascending=False)

    print("\n   TOP-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –≤ PCA:")
    for i, (feature, importance) in enumerate(feature_importance.head(10).items(), 1):
        print(f"      {i}. {feature}: {importance:.3f}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    importance_df = pd.DataFrame({
        'indicator_code': feature_importance.index,
        'pca_importance': feature_importance.values
    })

    importance_file = data_dir / 'pca_feature_importance.csv'
    importance_df.to_csv(importance_file, index=False)
    print(f"\n   ‚úÖ {importance_file}")

    # =============================
    # 5. –°–í–û–î–ö–ê
    # =============================
    print("\n" + "="*60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê:")
    print("="*60)
    print(f"‚úÖ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞: {corr_matrix.shape[0]}√ó{corr_matrix.shape[1]}")
    if top_10_df is not None:
        print(f"‚úÖ –¢–æ–ø-10 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å –Ω–∞—Å–µ–ª–µ–Ω–∏–µ–º")
    print(f"‚úÖ PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {n_components} (–æ–±—ä—è—Å–Ω–µ–Ω–æ {cumulative_variance[-1]*100:.2f}% –¥–∏—Å–ø–µ—Ä—Å–∏–∏)")
    print(f"‚úÖ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ PCA —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
    print("="*60)

    print(f"\nüìÇ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
    print(f"   ‚Ä¢ {data_dir}")
    print(f"   ‚Ä¢ {analysis_dir}")


if __name__ == '__main__':
    run_correlation_analysis()
